# Python Libraries, Frameworks and packages.

## Pytorch
The model and data pre-processing are implemented using `PyTorch` as an aspect, PyTorch is an open source machine learning (ML) framework based on the Python programming language and the Torch library (Yasar, 2022).

### How PyTorch was used (Pytorch.org, 2024):

- `Create_Datasets.py`
    - Imported the function `random_split(...)` from `torch.utils.data`, this functon is used to randomly split the dataset into     non-overlapping new datasets of given lengths, namely into validation, test and training datasets.


- `LSTM.py`
    - Imported `torch.nn` as `nn` and used the following functions: 
        - `nn.Embedding(...)`
        - `nn.LSTM(...)`
        - `nn.Linear(...)`
    - `nn.Embedding(...)`, used to make vectors of the words/tokens from the articles, so the model can map words or tokens to learnable vector representations.
    - `nn.LSTM(...)`, initializes a multi-layer LSTM Long Short-Term Memory network to process the sequential data.
    - `nn.Linear(...)`, creates a linear layer to map the output of an LSTM or any hidden layer to the desired output size, typically the number of classes or target values.


- `Train.py`
    - Imported `torch`, `torch.nn` as `nn`, `import torch.optim as optim` and `torch.utils.data import DataLoader, TensorDataset`
    - `torch` used by...
    - `torch.nn` used `nn.CrossEntropyLoss()` to initialize a cross-entropy loss function.
    - `torch.optim` initliazes the optimizer... (subject to change)
    - `torch.utils.data` made use of `TensorDataset` creates a PyTorch TensorDataset, to wrap the torch.Tensor objects (inputs and labels) into a dataset so they can be accessed together one sample at a time, later the samples are to be loaded into `DataLoader`.



- To use PyTorch to make an LSTM model the following steps are taken:
    - `import torch`
    - `import torch.nn`
    

It is particulary relevant to our chosen `LSTM` model because 

## Natural Language Toolkit (NLTK)

## Pandas

